---
title: "Untitled"
author: "Anastasia Bernat"
date: "5/12/2021"
output: html_document
---

```{r setup, include=FALSE}
rm(list=ls())
library(readxl)
library(dplyr)

dir = "/Users/anastasiabernat/Desktop/git_repositories/xml-archive/search_engine/"
setwd(dir)
knitr::opts_chunk$set(echo = TRUE)
```

## Read Source Files

```{r message=FALSE}
source_path = paste0(dir,"/src/")

script_names = c("get_cite_yr_range.R", # 1 function: get_citation_yr_range()
                 "plotting_helpers.R") 

for (script in script_names) { 
  path = paste0(source_path, script)
  source(path) 
}
```

## Read XLS file and remove unnecessary

1) Read XLS file

```{r message=FALSE}
keep_cols = c("Title","Authors","Corporate Authors","Editors","Book Editors","Source Title","Publication Date","Publication Year","Volume","Issue","Part Number","Supplement","Special Issue","Beginning Page","Ending Page","Article Number","DOI","Conference Title","Conference Date","Total Citations","Average per Year","1900","1901","1902","1903","1904","1905","1906","1907","1908","1909","1910","1911","1912","1913","1914","1915","1916","1917","1918","1919","1920","1921","1922","1923","1924","1925","1926","1927","1928","1929","1930","1931","1932","1933","1934","1935","1936","1937","1938","1939","1940","1941","1942","1943","1944","1945","1946","1947","1948","1949","1950","1951","1952","1953","1954","1955","1956","1957","1958","1959","1960","1961","1962","1963","1964","1965","1966","1967","1968","1969","1970","1971","1972","1973","1974","1975","1976","1977","1978","1979","1980","1981","1982","1983","1984","1985","1986","1987","1988","1989","1990","1991","1992","1993","1994","1995","1996","1997","1998","1999")

clean_cite_data = function(d, cnames) {
  colnames(d) = cnames
  d = d[29:nrow(d),]
  return(d)
}

data1 <- read_excel("xls_exports/WCUSA-search-1.xls")
data2 <- read_excel("xls_exports/WCUSA-search-2.xls")

cite1 <- read_excel("xls_exports/WCUSA-cite-1.xls")
cite2 <- read_excel("xls_exports/WCUSA-cite-2.xls")

cite1 = clean_cite_data(cite1, keep_cols)
cite2 = clean_cite_data(cite2, keep_cols)

dataWCUSA= rbind(data1, data2)
citesWCUSA = rbind(cite1, cite2)
```

```{r message=FALSE}
data1A <- read_excel("xls_exports/TS9J2-search-1.xls")
data2A <- read_excel("xls_exports/TS9J2-search-2.xls")
data3A <- read_excel("xls_exports/TS9J2-search-3.xls")

data1B <- read_excel("xls_exports/BAJ2-search-1.xls")
data2B <- read_excel("xls_exports/BAJ2-search-2.xls")
data3B <- read_excel("xls_exports/BAJ2-search-3.xls")
data4B <- read_excel("xls_exports/BAJ2-search-4.xls")
data5B <- read_excel("xls_exports/BAJ2-search-5.xls")
data6B <- read_excel("xls_exports/BAJ2-search-6.xls")
data7B <- read_excel("xls_exports/BAJ2-search-7.xls")
data8B <- read_excel("xls_exports/BAJ2-search-8.xls")
data9B <- read_excel("xls_exports/BAJ2-search-9.xls")
data10B <- read_excel("xls_exports/BAJ2-search-10.xls")
data11B <- read_excel("xls_exports/BAJ2-search-11.xls")
data12B <- read_excel("xls_exports/BAJ2-search-12.xls")

cite1A <- read_excel("xls_exports/TS9J2-cite-1.xls")
cite2A <- read_excel("xls_exports/TS9J2-cite-2.xls")
cite3A <- read_excel("xls_exports/TS9J2-cite-3.xls")

cite1B <- read_excel("xls_exports/BAJ2-cite-1.xls")
cite2B <- read_excel("xls_exports/BAJ2-cite-2.xls")
cite3B <- read_excel("xls_exports/BAJ2-cite-3.xls")
cite4B <- read_excel("xls_exports/BAJ2-cite-4.xls")
cite5B <- read_excel("xls_exports/BAJ2-cite-5.xls")
cite6B <- read_excel("xls_exports/BAJ2-cite-6.xls")
cite7B <- read_excel("xls_exports/BAJ2-cite-7.xls")
cite8B <- read_excel("xls_exports/BAJ2-cite-8.xls")
cite9B <- read_excel("xls_exports/BAJ2-cite-9.xls")
cite10B <- read_excel("xls_exports/BAJ2-cite-10.xls")
cite11B <- read_excel("xls_exports/BAJ2-cite-11.xls")
cite12B <- read_excel("xls_exports/BAJ2-cite-12.xls")

cite1A = clean_cite_data(cite1A, keep_cols)
cite2A = clean_cite_data(cite2A, keep_cols)
cite3A = clean_cite_data(cite3A, keep_cols)

cite1B = clean_cite_data(cite1B, keep_cols)
cite2B = clean_cite_data(cite2B, keep_cols)
cite3B = clean_cite_data(cite3B, keep_cols)
cite4B = clean_cite_data(cite4B, keep_cols)
cite5B = clean_cite_data(cite5B, keep_cols)
cite6B = clean_cite_data(cite6B, keep_cols)
cite7B = clean_cite_data(cite7B, keep_cols)
cite8B = clean_cite_data(cite8B, keep_cols)
cite9B = clean_cite_data(cite9B, keep_cols)
cite10B = clean_cite_data(cite10B, keep_cols)
cite11B = clean_cite_data(cite11B, keep_cols)
cite12B = clean_cite_data(cite12B, keep_cols)

dataTS9J2 = rbind(data1A,data2A,data3A)
dataBAJ2 = rbind(data1B,data2B,data3B,data4B,data5B,data6B,
                 data7B,data8B,data9B,data10B,data11B,data12B)
citesTS9J2 = rbind(cite1A,cite2A,cite3A)
citesBAJ2 = rbind(cite1B,cite2B,cite3B,cite4B,cite5B,cite6B,
                  cite7B,cite8B,cite9B,cite10B,cite11B,cite12B)
```

2) Remove unnecessary columns 

```{r warning=FALSE, message=FALSE}
remove_cols = c("Book Authors", "Book Editors", "Book Group Authors", "Book Author Full Names", 
                "Group Authors", "Book Series Title", "Book Series Subtitle", "Book DOI", 
                "Conference Title", "Conference Date", "Conference Location", "Conference Sponsor",
                "Conference Host", "Funding Orgs", "Funding Text", "Cited References", "ISBN",
                "Supplement", "Early Access Date", "...68", "Journal Abbreviation", 
                "Journal ISO Abbreviation", "WoS Categories", "Research Areas")
drop_identifiers = c("Email Addresses", "Researcher Ids", "ORCIDs", "ISSN", 
                     "eISSN", "IDS Number", "UT (Unique WOS ID)", "Pubmed Id")
drop_nuances = c("Cited Reference Count", "Times Cited, WoS Core", 
                 "180 Day Usage Count", "Highly Cited Status", "Hot Paper Status")

dWCUSA = dataWCUSA %>%
  select(-remove_cols) %>%
  select(-drop_identifiers) %>%
  select(-drop_nuances)
```

```{r}
dTS9J2 = dataTS9J2 %>%
  select(-remove_cols) %>%
  select(-drop_identifiers) %>%
  select(-drop_nuances)

dBAJ2 = dataBAJ2 %>%
  select(-remove_cols) %>%
  select(-drop_identifiers) %>%
  select(-drop_nuances)
```

```{r}
remove_cols = c("Corporate Authors","Editors","Book Editors","Supplement","Special Issue","Conference Title","Conference Date")

cWCUSA = citesWCUSA %>%
  select(-remove_cols)
```

```{r}
cTS9J2 = citesTS9J2 %>%
  select(-remove_cols)

cBAJ2 = citesBAJ2 %>%
  select(-remove_cols)
```

3) Clean inconsistent data entries

```{r}
cWCUSA$`Publication Year` = as.numeric(cWCUSA$`Publication Year`)
```

```{r}
cTS9J2$`Publication Year` = as.numeric(cTS9J2$`Publication Year`)
cBAJ2$`Publication Year` = as.numeric(cBAJ2$`Publication Year`)
```


4) Order the data by year and article title 

```{r}
doWCUSA = dWCUSA[order(-dWCUSA$`Publication Year`, dWCUSA$`Article Title`),]
coWCUSA = cWCUSA[order(-cWCUSA$`Publication Year`, cWCUSA$Title),]
```

```{r}
doTS9J2 = dTS9J2[order(-dTS9J2$`Publication Year`, dTS9J2$`Article Title`),]
doBAJ2 = dBAJ2[order(-dBAJ2$`Publication Year`, dBAJ2$`Article Title`),]

coTS9J2 = cTS9J2[order(-cTS9J2$`Publication Year`, cTS9J2$Title),]
coBAJ2 = cBAJ2[order(-cBAJ2$`Publication Year`, cBAJ2$Title),]
```

## Filtering

1) Filter out duplicates

```{r}
dfWCUSA = doWCUSA[!duplicated(doWCUSA$`Article Title`),]
cfWCUSA = coWCUSA[!duplicated(coWCUSA$Title),]
```

```{r}
dfTS9J2 = doTS9J2[!duplicated(doTS9J2$`Article Title`),]
dfBAJ2 = doBAJ2[!duplicated(doBAJ2$`Article Title`),]

cfTS9J2 = coTS9J2[!duplicated(coTS9J2$Title),]
cfBAJ2 = coBAJ2[!duplicated(coBAJ2$Title),]
```

2) Determine citation year range (str). [First year cited to the last year cited]

```{r}
cfWCUSAy = get_citation_yr_range(cfWCUSA, dfWCUSA)[[1]]
dfWCUSAy = get_citation_yr_range(cfWCUSA, dfWCUSA)[[2]]
```

```{r}
cfTS9J2y = get_citation_yr_range(cfTS9J2, dfTS9J2)[[1]]
dfTS9J2y = get_citation_yr_range(cfTS9J2, dfTS9J2)[[2]]

cfBAJ2y = get_citation_yr_range(cfBAJ2, dfBAJ2)[[1]]
dfBAJ2y = get_citation_yr_range(cfBAJ2, dfBAJ2)[[2]]
```


3) Compute the number times cited from 1900-1999.

```{r}
get_num_cited = function(cf, df) {
  
  years = cf[,18:length(cf)-3]
  cf$CiteT = rowSums(years) 
  df$CiteT = cf$CiteT 
  
  return(list(cf,df))
}
```

```{r}
cfWCUSAyn = get_num_cited(cfWCUSAy,dfWCUSAy)[[1]]
dfWCUSAyn = get_num_cited(cfWCUSAy,dfWCUSAy)[[2]]
```

```{r}
cfTS9J2yn = get_num_cited(cfTS9J2y,dfTS9J2y)[[1]]
dfTS9J2yn = get_num_cited(cfTS9J2y,dfTS9J2y)[[2]]

cfBAJ2yn = get_num_cited(cfBAJ2y,dfBAJ2y)[[1]]
dfBAJ2yn = get_num_cited(cfBAJ2y,dfBAJ2y)[[2]]
```

4) Compare citation metrics.

```{r}
dfWCUSAyn$CiteX = dfWCUSAyn$`Times Cited, All Databases` - dfWCUSAyn$`Since 2013 Usage Count`
compare = cbind(dfWCUSAyn$CiteT,dfWCUSAyn$CiteX)[1:10,] 
colnames(compare) = c("Times Cited (1900-1999) ", "Num Cited All Years - Cited Since 2013")
compare
```

It is probably the case that 2000 onwards, papers were cited much more frequently and it shows: http://apps.webofknowledge.com.proxy.uchicago.edu/summary.do?product=WOS&parentProduct=WOS&search_mode=CitationReport&qid=3&SID=5C1gNouD5pzsDOQyCCj&&page=1&action=sort&sortBy=PY.A;LD.A;SO.A.en;VL.A;PG.A;AU.A.en&showFirstPage=1&isCRHidden=false.

5) Create a plot that shows the year range on the x axis and on the y the number of times cited.

```{r}
dp1 = get_data_for_plotting(dfWCUSAyn)
generate_citation_plot(dp1)  # At first glance, it looks like the WC category retains papers that were most likely published from 1930 to 1960 and cited till the end of the century.

dp2 = get_data_for_plotting(dfTS9J2yn)
generate_citation_plot(dp2) # Noticing that this group has two groups: those cited since the 1920's and those cited since the 1970's.

dp3 = get_data_for_plotting(dfBAJ2yn)
generate_citation_plot(dp3) # This search mimics dp2, but it also has the most papers that were published from 1930-1960 and cited till the end of the century.
```

```{r}
# check overlapping articles using intersect()
overlapping_articles = intersect(dfTS9J2yn$`Article Title`,dfBAJ2yn$`Article Title`)
length(overlapping_articles) # all aritcles in dfTS9J2yn are in dfBAJ2yn

# remove overlapping articles from dfBAJ2yn
dfBAJ2ynR <- dfBAJ2yn[ ! dfBAJ2yn$`Article Title` %in% overlapping_articles, ]
```

```{r}
dfWCUSAyn$YrStart = as.numeric(dfWCUSAyn$YrStart) 
dfTS9J2yn$YrStart = as.numeric(dfTS9J2yn$YrStart) 
dfBAJ2yn$YrStart = as.numeric(dfBAJ2yn$YrStart) 

hist(dfWCUSAyn$YrStart, ylim=c(0,900), col="lightblue", breaks = 15, main="Year First Cited")
hist(dfTS9J2yn$YrStart, ylim=c(0,900), col="lightblue", breaks = 15, main="Year First Cited")
hist(dfBAJ2yn$YrStart, ylim=c(0,900), col="lightblue", breaks = 15, main="Year First Cited")

hist(dfWCUSAyn$`Publication Year`, ylim=c(0,900), breaks = 15, main="Year First Published")
hist(dfTS9J2yn$`Publication Year`, ylim=c(0,900), breaks = 15, main="Year First Published") # lose papers published from 1945-1970
hist(dfBAJ2yn$`Publication Year`, ylim=c(0,900), breaks = 15, main="Year First Published") # lose papers published from 1945-1970
```

Need to keep in mind that the WC dataset did not filter out for papers only published in the USA. That gap between 1945 and 1970 is most likely caused by location constraints.

```{r}
dp4 = get_data_for_plotting(dfBAJ2ynR)
generate_citation_plot(dp4) # removing dfTS9J2yn doesn't seem to make a dent in the overall composition of this pool of papers. Need to then check how necessary are these papers and why were they removed?

dfBAJ2ynR$YrStart = as.numeric(dfBAJ2ynR$YrStart) 
hist(dfBAJ2ynR$YrStart, ylim=c(0,900), col="lightblue", breaks = 15, main="Year First Cited")
hist(dfBAJ2ynR$`Publication Year`, ylim=c(0,900), breaks = 15, main="Year First Published") # mostly loose papers cited a lot near the end of the century and loose papers published near the end of the century
```

Notice: "In the 1960's, computer science came into its own as a discipline. In fact, the term was coined by George Forsythe, a numerical analyst. The first computer science department was formed at Purdue University in 1962." (https://cs.uwaterloo.ca/~shallit/Courses/134/history.html)

6) Compute some weighted or comparable factor.

```{r}
df$YrEnd = as.numeric(df$YrEnd)
df$YrStart = as.numeric(df$YrStart)
temp = df %>%
  filter(!is.na(YrEnd), !is.na(YrStart))
temp$Weight = temp$CiteT / (temp$YrEnd - temp$YrStart)
sort(temp$Weight)
# n_citations / range 
# If greater than 1 then citing more than once per year
# If lower than 1 then citing less than once per year
```

7) Assess zero-inflation.

```{r}
sum(df$CiteT == 0) / sum(df$CiteT) * 100 # Very low - only 0.36% zeros so let's keep the zeros
```

8) Create the masterlist.

a) Remove papers with citation counts of <= 0

```{r}
dd = df[df$CiteT >= 0, ] # all articles remained (there are no negatives)
```

b) Order by descending publication year and citation number. Store the intermediary step.

```{r}
dt = dd[order(-dd$`Publication Year`, -dd$CiteX),]
```

```{r}
write.csv(dt, "output/filtered_articles2.csv") 
```

c) Get top 10% or bottom 10% cited.

```{r}
unique(dt$`Publication Year`) # notice that there were no papers published before 1920
```

```{r}
# Top and bottom 10% 

q = 0.10
start_year = 1920
top_list = c()
bottom_list = c()
for (i in 1:8) {
  end_year = start_year + 10
  cat("Decade:", start_year, "to", end_year, "\n")
  
  df_decade = dt[dt$`Publication Year` >= start_year & dt$`Publication Year` < end_year,]
  df_sorted = df_decade[order(-df_decade$CiteT),]
  
  top5 = quantile(df_sorted$CiteT,  1-q)
  bottom5 = quantile(df_sorted$CiteT,  q)
  
  top = c()
  bottom = c()
  for (row in 1:nrow(df_sorted)) {
    paper = df_sorted[row, ]$`Article Title`
    cite_n = df_sorted[row, ]$CiteT
    if (cite_n > top5) {
      top = c(top, paper)
    }
    if (cite_n > bottom5) {
      bottom = c(bottom, paper)
    }
  }
  
  if (length(top) < 5) {read_nt = 3}
  else{read_nt=5}
  if (length(bottom) < 5) {read_nb = 3}
  else{read_nb=5}
  
  top_reading = sample(top, size=read_nt, replace=F)
  bottom_reading = sample(bottom, size=read_nb, replace=F)
  
  print(top_reading)
  print(bottom_reading)
  
  top_list = c(top_list, start_year)
  top_list = c(top_list, top_reading)
  bottom_list = c(bottom_list, start_year)
  bottom_list = c(bottom_list, bottom_reading)
  
  start_year = end_year
  
}
```

```{r}
datat = as.data.frame(top_list)
datat$group = "top"
datab = as.data.frame(bottom_list)
datab$group = "bottom"
colnames(datat) = c("", paste0("group",q))
colnames(datab) = c("", paste0("group",q))

masterlist = rbind(datat, datab)
masterlist$reader = ""

masterlist
```

## Write as a CSV file

```{r}
write.csv(masterlist, "output/masterlist3.csv") 
```
